// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
import { __rest } from "tslib";
/**
 * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!
 *
 * Any changes you make here may be lost.
 *
 * If you need to make changes, please do so in the original source file, \{project-root\}/sources/custom
 */
import { isTokenCredential } from "@azure/core-auth";
import { createOpenAI, getChatCompletions, getCompletions, getEmbeddings, getImages, listChatCompletions, listCompletions, } from "./api/index.js";
export class OpenAIClient {
    constructor(endpointOrOpenAiKey, credOrOptions = {}, options = {}) {
        var _a, _b;
        this._isAzure = false;
        let opts;
        let endpoint;
        let cred;
        if (isCred(credOrOptions)) {
            endpoint = endpointOrOpenAiKey;
            cred = credOrOptions;
            opts = options;
            this._isAzure = true;
        }
        else {
            endpoint = createOpenAIEndpoint(1);
            cred = endpointOrOpenAiKey;
            const { credentials } = credOrOptions, restOpts = __rest(credOrOptions, ["credentials"]);
            opts = Object.assign({ credentials: {
                    apiKeyHeaderName: (_a = credentials === null || credentials === void 0 ? void 0 : credentials.apiKeyHeaderName) !== null && _a !== void 0 ? _a : "Authorization",
                    scopes: credentials === null || credentials === void 0 ? void 0 : credentials.scopes,
                } }, restOpts);
        }
        this._client = createOpenAI(endpoint, cred, Object.assign(Object.assign({}, opts), (this._isAzure
            ? {}
            : {
                additionalPolicies: [
                    ...((_b = opts.additionalPolicies) !== null && _b !== void 0 ? _b : []),
                    {
                        position: "perCall",
                        policy: getPolicy(),
                    },
                ],
            })));
    }
    /**
     * Returns textual completions as configured for a given prompt.
     * @param deploymentName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this completions request.
     * @returns The completions for the given prompt.
     */
    getCompletions(deploymentName, prompt, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getCompletions(this._client, prompt, deploymentName, options);
    }
    /**
     * Lists the completions tokens as they become available for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The completions options for this completions request.
     * @returns An asynchronous iterable of completions tokens.
     */
    listCompletions(deploymentName, prompt, options = {}) {
        this.setModel(deploymentName, options);
        return listCompletions(this._client, prompt, deploymentName, options);
    }
    /**
     * Return the computed embeddings for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param input - The prompt to use for this request.
     * @param options - The embeddings options for this embeddings request.
     * @returns The embeddings for the given prompt.
     */
    getEmbeddings(deploymentName, input, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getEmbeddings(this._client, input, deploymentName, options);
    }
    /**
     * Get chat completions for provided chat context messages.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this completions request.
     * @returns The chat completions for the given chat context messages.
     */
    getChatCompletions(deploymentName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getChatCompletions(this._client, messages, deploymentName, options);
    }
    /**
     * Lists the chat completions tokens as they become available for a chat context.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this chat completions request.
     * @returns An asynchronous iterable of chat completions tokens.
     */
    listChatCompletions(deploymentName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return listChatCompletions(this._client, messages, deploymentName, options);
    }
    /**
     * Starts the generation of a batch of images from a text caption
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this image request.
     * @returns The image generation response (containing url or base64 data).
     */
    getImages(prompt, options = { requestOptions: {} }) {
        return getImages(this._client, prompt, options);
    }
    setModel(model, options) {
        if (!this._isAzure) {
            options.model = model;
        }
    }
}
function createOpenAIEndpoint(version) {
    return `https://api.openai.com/v${version}`;
}
function isCred(cred) {
    return isTokenCredential(cred) || cred.key !== undefined;
}
function getPolicy() {
    const policy = {
        name: "openAiEndpoint",
        sendRequest: (request, next) => {
            const obj = new URL(request.url);
            const parts = obj.pathname.split("/");
            switch (parts[parts.length - 1]) {
                case "completions":
                    if (parts[parts.length - 2] === "chat") {
                        obj.pathname = `/${parts[1]}/chat/completions`;
                    }
                    else {
                        obj.pathname = `/${parts[1]}/completions`;
                    }
                    break;
                case "embeddings":
                    obj.pathname = `/${parts[1]}/embeddings`;
                    break;
                case "generations:submit":
                    obj.pathname = `/${parts[1]}/images/generations`;
            }
            obj.searchParams.delete("api-version");
            request.url = obj.toString();
            return next(request);
        },
    };
    return policy;
}
//# sourceMappingURL=OpenAIClient.js.map