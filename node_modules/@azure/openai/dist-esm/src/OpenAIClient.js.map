{"version":3,"file":"OpenAIClient.js","sourceRoot":"","sources":["../../src/OpenAIClient.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;;AAElC;;;;;;GAMG;AAEH,OAAO,EAAkC,iBAAiB,EAAE,MAAM,kBAAkB,CAAC;AAErF,OAAO,EAGL,YAAY,EACZ,kBAAkB,EAClB,cAAc,EACd,aAAa,EACb,SAAS,EACT,mBAAmB,EACnB,eAAe,GAChB,MAAM,gBAAgB,CAAC;AAiBxB,MAAM,OAAO,YAAY;IAgCvB,YACE,mBAA2C,EAC3C,gBAAuE,EAAE,EACzE,UAA+B,EAAE;;QAjC3B,aAAQ,GAAG,KAAK,CAAC;QAmCvB,IAAI,IAAyB,CAAC;QAC9B,IAAI,QAAgB,CAAC;QACrB,IAAI,IAAqC,CAAC;QAC1C,IAAI,MAAM,CAAC,aAAa,CAAC,EAAE;YACzB,QAAQ,GAAG,mBAA6B,CAAC;YACzC,IAAI,GAAG,aAAa,CAAC;YACrB,IAAI,GAAG,OAAO,CAAC;YACf,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;SACtB;aAAM;YACL,QAAQ,GAAG,oBAAoB,CAAC,CAAC,CAAC,CAAC;YACnC,IAAI,GAAG,mBAAoC,CAAC;YAC5C,MAAM,EAAE,WAAW,KAAkB,aAAa,EAA1B,QAAQ,UAAK,aAAa,EAA5C,eAA4B,CAAgB,CAAC;YACnD,IAAI,mBACF,WAAW,EAAE;oBACX,gBAAgB,EAAE,MAAA,WAAW,aAAX,WAAW,uBAAX,WAAW,CAAE,gBAAgB,mCAAI,eAAe;oBAClE,MAAM,EAAE,WAAW,aAAX,WAAW,uBAAX,WAAW,CAAE,MAAM;iBAC5B,IACE,QAAQ,CACZ,CAAC;SACH;QAED,IAAI,CAAC,OAAO,GAAG,YAAY,CAAC,QAAQ,EAAE,IAAI,kCACrC,IAAI,GACJ,CAAC,IAAI,CAAC,QAAQ;YACf,CAAC,CAAC,EAAE;YACJ,CAAC,CAAC;gBACE,kBAAkB,EAAE;oBAClB,GAAG,CAAC,MAAA,IAAI,CAAC,kBAAkB,mCAAI,EAAE,CAAC;oBAClC;wBACE,QAAQ,EAAE,SAAS;wBACnB,MAAM,EAAE,SAAS,EAAE;qBACpB;iBACF;aACF,CAAC,EACN,CAAC;IACL,CAAC;IAED;;;;;;OAMG;IACH,cAAc,CACZ,cAAsB,EACtB,MAAgB,EAChB,UAAiC,EAAE,cAAc,EAAE,EAAE,EAAE;QAEvD,IAAI,CAAC,QAAQ,CAAC,cAAc,EAAE,OAAO,CAAC,CAAC;QACvC,OAAO,cAAc,CAAC,IAAI,CAAC,OAAO,EAAE,MAAM,EAAE,cAAc,EAAE,OAAO,CAAC,CAAC;IACvE,CAAC;IAED;;;;;;OAMG;IACH,eAAe,CACb,cAAsB,EACtB,MAAgB,EAChB,UAAiC,EAAE;QAEnC,IAAI,CAAC,QAAQ,CAAC,cAAc,EAAE,OAAO,CAAC,CAAC;QACvC,OAAO,eAAe,CAAC,IAAI,CAAC,OAAO,EAAE,MAAM,EAAE,cAAc,EAAE,OAAO,CAAC,CAAC;IACxE,CAAC;IAED;;;;;;OAMG;IACH,aAAa,CACX,cAAsB,EACtB,KAAe,EACf,UAAgC,EAAE,cAAc,EAAE,EAAE,EAAE;QAEtD,IAAI,CAAC,QAAQ,CAAC,cAAc,EAAE,OAAO,CAAC,CAAC;QACvC,OAAO,aAAa,CAAC,IAAI,CAAC,OAAO,EAAE,KAAK,EAAE,cAAc,EAAE,OAAO,CAAC,CAAC;IACrE,CAAC;IAED;;;;;;OAMG;IACH,kBAAkB,CAChB,cAAsB,EACtB,QAAuB,EACvB,UAAqC,EAAE,cAAc,EAAE,EAAE,EAAE;QAE3D,IAAI,CAAC,QAAQ,CAAC,cAAc,EAAE,OAAO,CAAC,CAAC;QACvC,OAAO,kBAAkB,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,EAAE,cAAc,EAAE,OAAO,CAAC,CAAC;IAC7E,CAAC;IAED;;;;;;OAMG;IACH,mBAAmB,CACjB,cAAsB,EACtB,QAAuB,EACvB,UAAqC,EAAE,cAAc,EAAE,EAAE,EAAE;QAE3D,IAAI,CAAC,QAAQ,CAAC,cAAc,EAAE,OAAO,CAAC,CAAC;QACvC,OAAO,mBAAmB,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,EAAE,cAAc,EAAE,OAAO,CAAC,CAAC;IAC9E,CAAC;IAED;;;;;OAKG;IACH,SAAS,CACP,MAAc,EACd,UAAkC,EAAE,cAAc,EAAE,EAAE,EAAE;QAExD,OAAO,SAAS,CAAC,IAAI,CAAC,OAAO,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC;IAClD,CAAC;IAEO,QAAQ,CAAC,KAAa,EAAE,OAA2B;QACzD,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;YAClB,OAAO,CAAC,KAAK,GAAG,KAAK,CAAC;SACvB;IACH,CAAC;CACF;AAED,SAAS,oBAAoB,CAAC,OAAe;IAC3C,OAAO,2BAA2B,OAAO,EAAE,CAAC;AAC9C,CAAC;AAED,SAAS,MAAM,CAAC,IAAyB;IACvC,OAAO,iBAAiB,CAAC,IAAI,CAAC,IAAI,IAAI,CAAC,GAAG,KAAK,SAAS,CAAC;AAC3D,CAAC;AAED,SAAS,SAAS;IAChB,MAAM,MAAM,GAAmB;QAC7B,IAAI,EAAE,gBAAgB;QACtB,WAAW,EAAE,CAAC,OAAO,EAAE,IAAI,EAAE,EAAE;YAC7B,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC;YACjC,MAAM,KAAK,GAAG,GAAG,CAAC,QAAQ,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;YACtC,QAAQ,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE;gBAC/B,KAAK,aAAa;oBAChB,IAAI,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,KAAK,MAAM,EAAE;wBACtC,GAAG,CAAC,QAAQ,GAAG,IAAI,KAAK,CAAC,CAAC,CAAC,mBAAmB,CAAC;qBAChD;yBAAM;wBACL,GAAG,CAAC,QAAQ,GAAG,IAAI,KAAK,CAAC,CAAC,CAAC,cAAc,CAAC;qBAC3C;oBACD,MAAM;gBACR,KAAK,YAAY;oBACf,GAAG,CAAC,QAAQ,GAAG,IAAI,KAAK,CAAC,CAAC,CAAC,aAAa,CAAC;oBACzC,MAAM;gBACR,KAAK,oBAAoB;oBACvB,GAAG,CAAC,QAAQ,GAAG,IAAI,KAAK,CAAC,CAAC,CAAC,qBAAqB,CAAC;aACpD;YACD,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;YACvC,OAAO,CAAC,GAAG,GAAG,GAAG,CAAC,QAAQ,EAAE,CAAC;YAC7B,OAAO,IAAI,CAAC,OAAO,CAAC,CAAC;QACvB,CAAC;KACF,CAAC;IACF,OAAO,MAAM,CAAC;AAChB,CAAC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\n/**\n * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!\n *\n * Any changes you make here may be lost.\n *\n * If you need to make changes, please do so in the original source file, \\{project-root\\}/sources/custom\n */\n\nimport { KeyCredential, TokenCredential, isTokenCredential } from \"@azure/core-auth\";\nimport { PipelinePolicy } from \"@azure/core-rest-pipeline\";\nimport {\n  OpenAIClientOptions,\n  OpenAIContext,\n  createOpenAI,\n  getChatCompletions,\n  getCompletions,\n  getEmbeddings,\n  getImages,\n  listChatCompletions,\n  listCompletions,\n} from \"./api/index.js\";\nimport {\n  ChatCompletions,\n  ChatMessage,\n  Completions,\n  Embeddings,\n  ImageGenerations,\n} from \"./models/models.js\";\nimport {\n  GetCompletionsOptions,\n  GetEmbeddingsOptions,\n  ImageGenerationOptions,\n} from \"./models/options.js\";\nimport { GetChatCompletionsOptions } from \"./api/models.js\";\n\nexport { OpenAIClientOptions } from \"./api/OpenAIContext.js\";\n\nexport class OpenAIClient {\n  private _client: OpenAIContext;\n  private _isAzure = false;\n\n  /**\n   * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.\n   * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.\n   *                 For example: https://my-resource.openai.azure.com.\n   * @param credential - A key credential used to authenticate to an Azure OpenAI resource.\n   * @param options - The options for configuring the client.\n   * @remarks\n   *   This constructor initializes an OpenAIClient object that can only be used with Azure OpenAI resources.\n   *   To use OpenAIClient with a non-Azure OpenAI inference endpoint, use a constructor that accepts a non-Azure OpenAI API key instead.\n   */\n  constructor(endpoint: string, credential: KeyCredential, options?: OpenAIClientOptions);\n  /**\n   * Initializes an instance of OpenAIClient for use with an Azure OpenAI resource.\n   * @param endpoint - The URI for an Azure OpenAI resource, including protocol and hostname.\n   *                 For example: https://my-resource.openai.azure.com.\n   * @param credential - A token credential used to authenticate with an Azure OpenAI resource.\n   * @param options - The options for configuring the client.\n   */\n  constructor(endpoint: string, credential: TokenCredential, options?: OpenAIClientOptions);\n  /**\n   * Initializes an instance of OpenAIClient for use with the non-Azure OpenAI endpoint.\n   * @param openAiApiKey - The API key to use when connecting to the non-Azure OpenAI endpoint.\n   * @param options - The options for configuring the client.\n   * @remarks\n   *   OpenAIClient objects initialized with this constructor can only be used with the non-Azure OpenAI inference endpoint.\n   *   To use OpenAIClient with an Azure OpenAI resource, use a constructor that accepts a resource URI and Azure authentication credential instead.\n   */\n  constructor(openAiApiKey: KeyCredential, options?: OpenAIClientOptions);\n  constructor(\n    endpointOrOpenAiKey: string | KeyCredential,\n    credOrOptions: KeyCredential | TokenCredential | OpenAIClientOptions = {},\n    options: OpenAIClientOptions = {}\n  ) {\n    let opts: OpenAIClientOptions;\n    let endpoint: string;\n    let cred: KeyCredential | TokenCredential;\n    if (isCred(credOrOptions)) {\n      endpoint = endpointOrOpenAiKey as string;\n      cred = credOrOptions;\n      opts = options;\n      this._isAzure = true;\n    } else {\n      endpoint = createOpenAIEndpoint(1);\n      cred = endpointOrOpenAiKey as KeyCredential;\n      const { credentials, ...restOpts } = credOrOptions;\n      opts = {\n        credentials: {\n          apiKeyHeaderName: credentials?.apiKeyHeaderName ?? \"Authorization\",\n          scopes: credentials?.scopes,\n        },\n        ...restOpts,\n      };\n    }\n\n    this._client = createOpenAI(endpoint, cred, {\n      ...opts,\n      ...(this._isAzure\n        ? {}\n        : {\n            additionalPolicies: [\n              ...(opts.additionalPolicies ?? []),\n              {\n                position: \"perCall\",\n                policy: getPolicy(),\n              },\n            ],\n          }),\n    });\n  }\n\n  /**\n   * Returns textual completions as configured for a given prompt.\n   * @param deploymentName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The options for this completions request.\n   * @returns The completions for the given prompt.\n   */\n  getCompletions(\n    deploymentName: string,\n    prompt: string[],\n    options: GetCompletionsOptions = { requestOptions: {} }\n  ): Promise<Completions> {\n    this.setModel(deploymentName, options);\n    return getCompletions(this._client, prompt, deploymentName, options);\n  }\n\n  /**\n   * Lists the completions tokens as they become available for a given prompt.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param prompt - The prompt to use for this request.\n   * @param options - The completions options for this completions request.\n   * @returns An asynchronous iterable of completions tokens.\n   */\n  listCompletions(\n    deploymentName: string,\n    prompt: string[],\n    options: GetCompletionsOptions = {}\n  ): AsyncIterable<Omit<Completions, \"usage\">> {\n    this.setModel(deploymentName, options);\n    return listCompletions(this._client, prompt, deploymentName, options);\n  }\n\n  /**\n   * Return the computed embeddings for a given prompt.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param input - The prompt to use for this request.\n   * @param options - The embeddings options for this embeddings request.\n   * @returns The embeddings for the given prompt.\n   */\n  getEmbeddings(\n    deploymentName: string,\n    input: string[],\n    options: GetEmbeddingsOptions = { requestOptions: {} }\n  ): Promise<Embeddings> {\n    this.setModel(deploymentName, options);\n    return getEmbeddings(this._client, input, deploymentName, options);\n  }\n\n  /**\n   * Get chat completions for provided chat context messages.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param messages - The chat context messages to use for this request.\n   * @param options - The chat completions options for this completions request.\n   * @returns The chat completions for the given chat context messages.\n   */\n  getChatCompletions(\n    deploymentName: string,\n    messages: ChatMessage[],\n    options: GetChatCompletionsOptions = { requestOptions: {} }\n  ): Promise<ChatCompletions> {\n    this.setModel(deploymentName, options);\n    return getChatCompletions(this._client, messages, deploymentName, options);\n  }\n\n  /**\n   * Lists the chat completions tokens as they become available for a chat context.\n   * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.\n   * @param messages - The chat context messages to use for this request.\n   * @param options - The chat completions options for this chat completions request.\n   * @returns An asynchronous iterable of chat completions tokens.\n   */\n  listChatCompletions(\n    deploymentName: string,\n    messages: ChatMessage[],\n    options: GetChatCompletionsOptions = { requestOptions: {} }\n  ): AsyncIterable<ChatCompletions> {\n    this.setModel(deploymentName, options);\n    return listChatCompletions(this._client, messages, deploymentName, options);\n  }\n\n  /**\n   * Starts the generation of a batch of images from a text caption\n   * @param prompt - The prompt to use for this request.\n   * @param options - The options for this image request.\n   * @returns The image generation response (containing url or base64 data).\n   */\n  getImages(\n    prompt: string,\n    options: ImageGenerationOptions = { requestOptions: {} }\n  ): Promise<ImageGenerations> {\n    return getImages(this._client, prompt, options);\n  }\n\n  private setModel(model: string, options: { model?: string }): void {\n    if (!this._isAzure) {\n      options.model = model;\n    }\n  }\n}\n\nfunction createOpenAIEndpoint(version: number): string {\n  return `https://api.openai.com/v${version}`;\n}\n\nfunction isCred(cred: Record<string, any>): cred is TokenCredential | KeyCredential {\n  return isTokenCredential(cred) || cred.key !== undefined;\n}\n\nfunction getPolicy(): PipelinePolicy {\n  const policy: PipelinePolicy = {\n    name: \"openAiEndpoint\",\n    sendRequest: (request, next) => {\n      const obj = new URL(request.url);\n      const parts = obj.pathname.split(\"/\");\n      switch (parts[parts.length - 1]) {\n        case \"completions\":\n          if (parts[parts.length - 2] === \"chat\") {\n            obj.pathname = `/${parts[1]}/chat/completions`;\n          } else {\n            obj.pathname = `/${parts[1]}/completions`;\n          }\n          break;\n        case \"embeddings\":\n          obj.pathname = `/${parts[1]}/embeddings`;\n          break;\n        case \"generations:submit\":\n          obj.pathname = `/${parts[1]}/images/generations`;\n      }\n      obj.searchParams.delete(\"api-version\");\n      request.url = obj.toString();\n      return next(request);\n    },\n  };\n  return policy;\n}\n"]}