'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var coreAuth = require('@azure/core-auth');
var tslib = require('tslib');
var coreClient = require('@azure-rest/core-client');
var logger$1 = require('@azure/logger');
var coreLro = require('@azure/core-lro');

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * The OpenAIKeyCredential class represents an OpenAI API key
 * and is used to authenticate into an OpenAI client for
 * an OpenAI endpoint.
 */
class OpenAIKeyCredential {
    /**
     * Create an instance of an AzureKeyCredential for use
     * with a service client.
     *
     * @param key - The initial value of the key to use in authentication
     */
    constructor(key) {
        if (!key) {
            throw new Error("key must be a non-empty string");
        }
        this._key = createKey(key);
    }
    /**
     * The value of the key to be used in authentication
     */
    get key() {
        return this._key;
    }
    /**
     * Change the value of the key.
     *
     * Updates will take effect upon the next request after
     * updating the key value.
     *
     * @param newKey - The new key value to be used
     */
    update(newKey) {
        this._key = createKey(newKey);
    }
}
function createKey(key) {
    return key.startsWith("Bearer ") ? key : `Bearer ${key}`;
}

// Copyright (c) Microsoft Corporation.
const logger = logger$1.createClientLogger("openai");

// Copyright (c) Microsoft Corporation.
/**
 * Initialize a new instance of `OpenAIContext`
 * @param endpoint - Supported Cognitive Services endpoints (protocol and hostname, for example:
 * https://westus.api.cognitive.microsoft.com).
 * @param credentials - uniquely identify client credential
 * @param options - the parameter for all optional parameters
 */
function createClient(endpoint, credentials, options = {}) {
    var _a, _b, _c, _d, _e, _f, _g, _h;
    const baseUrl = (_a = options.baseUrl) !== null && _a !== void 0 ? _a : `${endpoint}/openai`;
    options.apiVersion = (_b = options.apiVersion) !== null && _b !== void 0 ? _b : "2023-08-01-preview";
    options = Object.assign(Object.assign({}, options), { credentials: {
            scopes: (_d = (_c = options.credentials) === null || _c === void 0 ? void 0 : _c.scopes) !== null && _d !== void 0 ? _d : ["https://cognitiveservices.azure.com/.default"],
            apiKeyHeaderName: (_f = (_e = options.credentials) === null || _e === void 0 ? void 0 : _e.apiKeyHeaderName) !== null && _f !== void 0 ? _f : "api-key",
        } });
    const userAgentInfo = `azsdk-js-openai-rest/1.0.0-beta.5`;
    const userAgentPrefix = options.userAgentOptions && options.userAgentOptions.userAgentPrefix
        ? `${options.userAgentOptions.userAgentPrefix} ${userAgentInfo}`
        : `${userAgentInfo}`;
    options = Object.assign(Object.assign({}, options), { userAgentOptions: {
            userAgentPrefix,
        }, loggingOptions: {
            logger: (_h = (_g = options.loggingOptions) === null || _g === void 0 ? void 0 : _g.logger) !== null && _h !== void 0 ? _h : logger.info,
        } });
    const client = coreClient.getClient(baseUrl, credentials, options);
    return client;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
const responseMap = {
    "POST /deployments/{deploymentId}/embeddings": ["200"],
    "POST /deployments/{deploymentId}/completions": ["200"],
    "POST /deployments/{deploymentId}/chat/completions": ["200"],
    "POST /deployments/{deploymentId}/extensions/chat/completions": ["200"],
    "GET /operations/images/{operationId}": ["200"],
    "POST /images/generations:submit": ["202"],
    "GET /images/generations:submit": ["200", "202"],
};
function isUnexpected(response) {
    const lroOriginal = response.headers["x-ms-original-url"];
    const url = new URL(lroOriginal !== null && lroOriginal !== void 0 ? lroOriginal : response.request.url);
    const method = response.request.method;
    let pathDetails = responseMap[`${method} ${url.pathname}`];
    if (!pathDetails) {
        pathDetails = getParametrizedPathSuccess(method, url.pathname);
    }
    return !pathDetails.includes(response.status);
}
function getParametrizedPathSuccess(method, path) {
    var _a, _b, _c, _d;
    const pathParts = path.split("/");
    // Traverse list to match the longest candidate
    // matchedLen: the length of candidate path
    // matchedValue: the matched status code array
    let matchedLen = -1, matchedValue = [];
    // Iterate the responseMap to find a match
    for (const [key, value] of Object.entries(responseMap)) {
        // Extracting the path from the map key which is in format
        // GET /path/foo
        if (!key.startsWith(method)) {
            continue;
        }
        const candidatePath = getPathFromMapKey(key);
        // Get each part of the url path
        const candidateParts = candidatePath.split("/");
        // track if we have found a match to return the values found.
        let found = true;
        for (let i = candidateParts.length - 1, j = pathParts.length - 1; i >= 1 && j >= 1; i--, j--) {
            if (((_a = candidateParts[i]) === null || _a === void 0 ? void 0 : _a.startsWith("{")) && ((_b = candidateParts[i]) === null || _b === void 0 ? void 0 : _b.indexOf("}")) !== -1) {
                const start = candidateParts[i].indexOf("}") + 1, end = (_c = candidateParts[i]) === null || _c === void 0 ? void 0 : _c.length;
                // If the current part of the candidate is a "template" part
                // Try to use the suffix of pattern to match the path
                // {guid} ==> $
                // {guid}:export ==> :export$
                const isMatched = new RegExp(`${(_d = candidateParts[i]) === null || _d === void 0 ? void 0 : _d.slice(start, end)}`).test(pathParts[j] || "");
                if (!isMatched) {
                    found = false;
                    break;
                }
                continue;
            }
            // If the candidate part is not a template and
            // the parts don't match mark the candidate as not found
            // to move on with the next candidate path.
            if (candidateParts[i] !== pathParts[j]) {
                found = false;
                break;
            }
        }
        // We finished evaluating the current candidate parts
        // Update the matched value if and only if we found the longer pattern
        if (found && candidatePath.length > matchedLen) {
            matchedLen = candidatePath.length;
            matchedValue = value;
        }
    }
    return matchedValue;
}
function getPathFromMapKey(mapKey) {
    const pathStart = mapKey.indexOf("/");
    return mapKey.slice(pathStart);
}

// Copyright (c) Microsoft Corporation.
async function getLongRunningPoller(client, initialResponse, options = {}) {
    var _a;
    const poller = {
        requestMethod: initialResponse.request.method,
        requestPath: initialResponse.request.url,
        sendInitialRequest: async () => {
            // In the case of Rest Clients we are building the LRO poller object from a response that's the reason
            // we are not triggering the initial request here, just extracting the information from the
            // response we were provided.
            return getLroResponse(initialResponse);
        },
        sendPollRequest: async (path) => {
            // This is the callback that is going to be called to poll the service
            // to get the latest status. We use the client provided and the polling path
            // which is an opaque URL provided by caller, the service sends this in one of the following headers: operation-location, azure-asyncoperation or location
            // depending on the lro pattern that the service implements. If non is provided we default to the initial path.
            const response = await client.pathUnchecked(path !== null && path !== void 0 ? path : initialResponse.request.url).get();
            const lroResponse = getLroResponse(response);
            lroResponse.rawResponse.headers["x-ms-original-url"] = initialResponse.request.url;
            return lroResponse;
        },
    };
    options.resolveOnUnsuccessful = (_a = options.resolveOnUnsuccessful) !== null && _a !== void 0 ? _a : true;
    return coreLro.createHttpPoller(poller, options);
}
/**
 * Converts a Rest Client response to a response that the LRO implementation understands
 * @param response - a rest client http response
 * @returns - An LRO response that the LRO implementation understands
 */
function getLroResponse(response) {
    if (Number.isNaN(response.status)) {
        throw new TypeError(`Status code of the response is not a number. Value: ${response.status}`);
    }
    return {
        flatResponse: response,
        rawResponse: Object.assign(Object.assign({}, response), { statusCode: Number.parseInt(response.status), body: response.body }),
    };
}

// Copyright (c) Microsoft Corporation.
/** Azure OpenAI APIs for completions and search */
function createOpenAI(endpoint, credential, options = {}) {
    const baseUrl = endpoint;
    const clientContext = createClient(baseUrl, credential, options);
    return clientContext;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
function getCompletionsResult(body) {
    var _a;
    return Object.assign(Object.assign({ id: body["id"], created: new Date(body["created"]) }, (!body["prompt_annotations"]
        ? {}
        : {
            promptFilterResults: body["prompt_annotations"].map((p) => (Object.assign({ promptIndex: p["prompt_index"] }, (!p.content_filter_results
                ? {}
                : {
                    contentFilterResults: deserializeContentFilter(p.content_filter_results),
                })))),
        })), { choices: ((_a = body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => (Object.assign(Object.assign({ text: p["text"], index: p["index"] }, (!p.content_filter_results
            ? {}
            : {
                contentFilterResults: deserializeContentFilter(p.content_filter_results),
            })), { logprobs: p.logprobs === null
                ? null
                : {
                    tokens: p.logprobs["tokens"],
                    tokenLogprobs: p.logprobs["token_logprobs"],
                    topLogprobs: p.logprobs["top_logprobs"],
                    textOffset: p.logprobs["text_offset"],
                }, finishReason: p["finish_reason"] }))) });
}
function getChatCompletionsResult(body) {
    var _a;
    return Object.assign({ id: body["id"], created: new Date(body["created"]), choices: ((_a = body["choices"]) !== null && _a !== void 0 ? _a : []).map((p) => (Object.assign(Object.assign(Object.assign(Object.assign({}, (!p.message ? {} : { message: _deserializeMessage(p.message) })), { index: p["index"], finishReason: p["finish_reason"] }), (!p.delta ? {} : { delta: _deserializeMessage(p.delta) })), (!p.content_filter_results
            ? {}
            : { contentFilterResults: deserializeContentFilter(p.content_filter_results) })))) }, (!body["prompt_annotations"]
        ? {}
        : {
            promptFilterResults: body["prompt_annotations"].map((p) => (Object.assign({ promptIndex: p["prompt_index"] }, (!p.content_filter_results
                ? {}
                : {
                    contentFilterResults: deserializeContentFilter(p.content_filter_results),
                })))),
        }));
}
function _deserializeMessage(message) {
    var _a, _b;
    return Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, (!message["role"] ? {} : { role: message["role"] })), (!message["content"] ? {} : { content: message["content"] })), (!message["name"] ? {} : { name: message["name"] })), (!message.function_call
        ? {}
        : {
            functionCall: {
                name: (_a = message.function_call) === null || _a === void 0 ? void 0 : _a["name"],
                arguments: (_b = message.function_call) === null || _b === void 0 ? void 0 : _b["arguments"],
            },
        })), (!message.context
        ? {}
        : {
            context: Object.assign({}, (!message.context.messages
                ? {}
                : {
                    messages: message.context.messages.map((m) => {
                        return _deserializeMessage(m);
                    }),
                })),
        }));
}
function deserializeContentFilter(result) {
    var _a, _b, _c, _d, _e, _f, _g, _h;
    return Object.assign(Object.assign(Object.assign(Object.assign({}, (!result.sexual
        ? {}
        : {
            sexual: {
                severity: (_a = result.sexual) === null || _a === void 0 ? void 0 : _a["severity"],
                filtered: (_b = result.sexual) === null || _b === void 0 ? void 0 : _b["filtered"],
            },
        })), (!result.violence
        ? {}
        : {
            violence: {
                severity: (_c = result.violence) === null || _c === void 0 ? void 0 : _c["severity"],
                filtered: (_d = result.violence) === null || _d === void 0 ? void 0 : _d["filtered"],
            },
        })), (!result.hate
        ? {}
        : {
            hate: {
                severity: (_e = result.hate) === null || _e === void 0 ? void 0 : _e["severity"],
                filtered: (_f = result.hate) === null || _f === void 0 ? void 0 : _f["filtered"],
            },
        })), (!result.self_harm
        ? {}
        : {
            selfHarm: {
                severity: (_g = result.self_harm) === null || _g === void 0 ? void 0 : _g["severity"],
                filtered: (_h = result.self_harm) === null || _h === void 0 ? void 0 : _h["filtered"],
            },
        }));
}

// Copyright (c) Microsoft Corporation.
function toSSE(chunkIter) {
    return toMessage(toLine(chunkIter));
}
function concatBuffer(a, b) {
    const res = new Uint8Array(a.length + b.length);
    res.set(a);
    res.set(b, a.length);
    return res;
}
function createMessage() {
    return {
        data: undefined,
        event: "",
        id: "",
        retry: undefined,
    };
}
function toLine(chunkIter) {
    return tslib.__asyncGenerator(this, arguments, function* toLine_1() {
        var _a, e_1, _b, _c;
        let buf;
        let bufIdx = 0;
        let fieldLen = -1;
        let discardTrailingNewline = false;
        try {
            for (var _d = true, chunkIter_1 = tslib.__asyncValues(chunkIter), chunkIter_1_1; chunkIter_1_1 = yield tslib.__await(chunkIter_1.next()), _a = chunkIter_1_1.done, !_a;) {
                _c = chunkIter_1_1.value;
                _d = false;
                try {
                    const chunk = _c;
                    if (buf === undefined) {
                        buf = chunk;
                        bufIdx = 0;
                        fieldLen = -1;
                    }
                    else {
                        buf = concatBuffer(buf, chunk);
                    }
                    const bufLen = buf.length;
                    let start = 0;
                    while (bufIdx < bufLen) {
                        if (discardTrailingNewline) {
                            if (buf[bufIdx] === 10 /* ControlChars.NewLine */) {
                                start = ++bufIdx;
                            }
                            discardTrailingNewline = false;
                        }
                        let end = -1;
                        for (; bufIdx < bufLen && end === -1; ++bufIdx) {
                            switch (buf[bufIdx]) {
                                case 58 /* ControlChars.Colon */:
                                    if (fieldLen === -1) {
                                        fieldLen = bufIdx - start;
                                    }
                                    break;
                                case 13 /* ControlChars.CarriageReturn */:
                                    // We need to discard the trailing newline if any but can't do
                                    // that now because we need to dispatch the current line first.
                                    discardTrailingNewline = true;
                                    end = bufIdx;
                                    break;
                                case 10 /* ControlChars.NewLine */:
                                    end = bufIdx;
                                    break;
                            }
                        }
                        if (end === -1) {
                            // We reached the end of the buffer but the line hasn't ended.
                            // Wait for the next chunk and then continue parsing:
                            break;
                        }
                        yield yield tslib.__await({ line: buf.subarray(start, end), fieldLen });
                        start = bufIdx; // we're now on the next line
                        fieldLen = -1;
                    }
                    if (start === bufLen) {
                        buf = undefined;
                    }
                    else if (start !== 0) {
                        // discard already processed lines
                        buf = buf.subarray(start);
                        bufIdx -= start;
                    }
                }
                finally {
                    _d = true;
                }
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (!_d && !_a && (_b = chunkIter_1.return)) yield tslib.__await(_b.call(chunkIter_1));
            }
            finally { if (e_1) throw e_1.error; }
        }
    });
}
function toMessage(lineIter) {
    return tslib.__asyncGenerator(this, arguments, function* toMessage_1() {
        var _a, e_2, _b, _c;
        let message = createMessage();
        const decoder = new TextDecoder();
        try {
            for (var _d = true, lineIter_1 = tslib.__asyncValues(lineIter), lineIter_1_1; lineIter_1_1 = yield tslib.__await(lineIter_1.next()), _a = lineIter_1_1.done, !_a;) {
                _c = lineIter_1_1.value;
                _d = false;
                try {
                    const { line, fieldLen } = _c;
                    if (line.length === 0 && message.data !== undefined) {
                        // empty line denotes end of message. Yield and start a new message:
                        yield yield tslib.__await(message);
                        message = createMessage();
                    }
                    else if (fieldLen > 0) {
                        // exclude comments and lines with no values
                        // line is of format "<field>:<value>" or "<field>: <value>"
                        // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation
                        const field = decoder.decode(line.subarray(0, fieldLen));
                        const valueOffset = fieldLen + (line[fieldLen + 1] === 32 /* ControlChars.Space */ ? 2 : 1);
                        const value = decoder.decode(line.subarray(valueOffset));
                        switch (field) {
                            case "data":
                                message.data = message.data ? message.data + "\n" + value : value;
                                break;
                            case "event":
                                message.event = value;
                                break;
                            case "id":
                                message.id = value;
                                break;
                            case "retry": {
                                const retry = parseInt(value, 10);
                                if (!isNaN(retry)) {
                                    message.retry = retry;
                                }
                                break;
                            }
                        }
                    }
                }
                finally {
                    _d = true;
                }
            }
        }
        catch (e_2_1) { e_2 = { error: e_2_1 }; }
        finally {
            try {
                if (!_d && !_a && (_b = lineIter_1.return)) yield tslib.__await(_b.call(lineIter_1));
            }
            finally { if (e_2) throw e_2.error; }
        }
    });
}

// Copyright (c) Microsoft Corporation.
async function getSSEs(response) {
    const chunkIterator = await getStream(response);
    return toSSE(chunkIterator);
}
async function getStream(response) {
    const stream = (await response.asNodeStream()).body;
    if (!stream)
        throw new Error("No stream found in response. Did you enable the stream option?");
    return stream;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
/**
 * THIS IS AN AUTO-GENERATED FILE - DO NOT EDIT!
 *
 * Any changes you make here may be lost.
 *
 * If you need to make changes, please do so in the original source file, \{project-root\}/sources/custom
 */
function wrapError(f, message) {
    try {
        const result = f();
        return result;
    }
    catch (cause) {
        throw new Error(message, { cause });
    }
}

// Copyright (c) Microsoft Corporation.
function getOaiSSEs(response, toEvent) {
    return tslib.__asyncGenerator(this, arguments, function* getOaiSSEs_1() {
        var _a, e_1, _b, _c;
        const stream = yield tslib.__await(getSSEs(response));
        let isDone = false;
        try {
            for (var _d = true, stream_1 = tslib.__asyncValues(stream), stream_1_1; stream_1_1 = yield tslib.__await(stream_1.next()), _a = stream_1_1.done, !_a;) {
                _c = stream_1_1.value;
                _d = false;
                try {
                    const event = _c;
                    if (isDone) {
                        // handle a case where the service sends excess stream
                        // data after the [DONE] event
                        continue;
                    }
                    else if (event.data === "[DONE]") {
                        isDone = true;
                    }
                    else {
                        yield yield tslib.__await(toEvent(wrapError(() => JSON.parse(event.data), "Error parsing an event. See 'cause' for more details")));
                    }
                }
                finally {
                    _d = true;
                }
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (!_d && !_a && (_b = stream_1.return)) yield tslib.__await(_b.call(stream_1));
            }
            finally { if (e_1) throw e_1.error; }
        }
    });
}

// Copyright (c) Microsoft Corporation.
function _getEmbeddingsSend(context, input, deploymentId, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/embeddings", deploymentId).post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: { user: options === null || options === void 0 ? void 0 : options.user, model: options === null || options === void 0 ? void 0 : options.model, input: input } }));
}
async function _getEmbeddingsDeserialize(result) {
    var _a;
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return {
        data: ((_a = result.body["data"]) !== null && _a !== void 0 ? _a : []).map((p) => ({
            embedding: p["embedding"],
            index: p["index"],
        })),
        usage: {
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/** Return the embeddings for a given prompt. */
async function getEmbeddings(context, input, deploymentId, options = { requestOptions: {} }) {
    const result = await _getEmbeddingsSend(context, input, deploymentId, options);
    return _getEmbeddingsDeserialize(result);
}
function _getCompletionsSend(context, prompt, deploymentId, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/completions", deploymentId).post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: {
            prompt: prompt,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            logprobs: options === null || options === void 0 ? void 0 : options.logprobs,
            echo: options === null || options === void 0 ? void 0 : options.echo,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            best_of: options === null || options === void 0 ? void 0 : options.bestOf,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
        } }));
}
async function _getCompletionsDeserialize(result) {
    var _a, _b;
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return {
        id: result.body["id"],
        created: new Date(result.body["created"]),
        promptFilterResults: ((_a = result.body["prompt_annotations"]) !== null && _a !== void 0 ? _a : []).map((p) => {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v;
            return ({
                promptIndex: p["prompt_index"],
                contentFilterResults: !p.content_filter_results
                    ? undefined
                    : {
                        sexual: !((_a = p.content_filter_results) === null || _a === void 0 ? void 0 : _a.sexual)
                            ? undefined
                            : {
                                severity: (_c = (_b = p.content_filter_results) === null || _b === void 0 ? void 0 : _b.sexual) === null || _c === void 0 ? void 0 : _c["severity"],
                                filtered: (_e = (_d = p.content_filter_results) === null || _d === void 0 ? void 0 : _d.sexual) === null || _e === void 0 ? void 0 : _e["filtered"],
                            },
                        violence: !((_f = p.content_filter_results) === null || _f === void 0 ? void 0 : _f.violence)
                            ? undefined
                            : {
                                severity: (_h = (_g = p.content_filter_results) === null || _g === void 0 ? void 0 : _g.violence) === null || _h === void 0 ? void 0 : _h["severity"],
                                filtered: (_k = (_j = p.content_filter_results) === null || _j === void 0 ? void 0 : _j.violence) === null || _k === void 0 ? void 0 : _k["filtered"],
                            },
                        hate: !((_l = p.content_filter_results) === null || _l === void 0 ? void 0 : _l.hate)
                            ? undefined
                            : {
                                severity: (_o = (_m = p.content_filter_results) === null || _m === void 0 ? void 0 : _m.hate) === null || _o === void 0 ? void 0 : _o["severity"],
                                filtered: (_q = (_p = p.content_filter_results) === null || _p === void 0 ? void 0 : _p.hate) === null || _q === void 0 ? void 0 : _q["filtered"],
                            },
                        selfHarm: !((_r = p.content_filter_results) === null || _r === void 0 ? void 0 : _r.self_harm)
                            ? undefined
                            : {
                                severity: (_t = (_s = p.content_filter_results) === null || _s === void 0 ? void 0 : _s.self_harm) === null || _t === void 0 ? void 0 : _t["severity"],
                                filtered: (_v = (_u = p.content_filter_results) === null || _u === void 0 ? void 0 : _u.self_harm) === null || _v === void 0 ? void 0 : _v["filtered"],
                            },
                    },
            });
        }),
        choices: ((_b = result.body["choices"]) !== null && _b !== void 0 ? _b : []).map((p) => {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v;
            return ({
                text: p["text"],
                index: p["index"],
                contentFilterResults: !p.content_filter_results
                    ? undefined
                    : {
                        sexual: !((_a = p.content_filter_results) === null || _a === void 0 ? void 0 : _a.sexual)
                            ? undefined
                            : {
                                severity: (_c = (_b = p.content_filter_results) === null || _b === void 0 ? void 0 : _b.sexual) === null || _c === void 0 ? void 0 : _c["severity"],
                                filtered: (_e = (_d = p.content_filter_results) === null || _d === void 0 ? void 0 : _d.sexual) === null || _e === void 0 ? void 0 : _e["filtered"],
                            },
                        violence: !((_f = p.content_filter_results) === null || _f === void 0 ? void 0 : _f.violence)
                            ? undefined
                            : {
                                severity: (_h = (_g = p.content_filter_results) === null || _g === void 0 ? void 0 : _g.violence) === null || _h === void 0 ? void 0 : _h["severity"],
                                filtered: (_k = (_j = p.content_filter_results) === null || _j === void 0 ? void 0 : _j.violence) === null || _k === void 0 ? void 0 : _k["filtered"],
                            },
                        hate: !((_l = p.content_filter_results) === null || _l === void 0 ? void 0 : _l.hate)
                            ? undefined
                            : {
                                severity: (_o = (_m = p.content_filter_results) === null || _m === void 0 ? void 0 : _m.hate) === null || _o === void 0 ? void 0 : _o["severity"],
                                filtered: (_q = (_p = p.content_filter_results) === null || _p === void 0 ? void 0 : _p.hate) === null || _q === void 0 ? void 0 : _q["filtered"],
                            },
                        selfHarm: !((_r = p.content_filter_results) === null || _r === void 0 ? void 0 : _r.self_harm)
                            ? undefined
                            : {
                                severity: (_t = (_s = p.content_filter_results) === null || _s === void 0 ? void 0 : _s.self_harm) === null || _t === void 0 ? void 0 : _t["severity"],
                                filtered: (_v = (_u = p.content_filter_results) === null || _u === void 0 ? void 0 : _u.self_harm) === null || _v === void 0 ? void 0 : _v["filtered"],
                            },
                    },
                logprobs: p.logprobs === null
                    ? null
                    : {
                        tokens: p.logprobs["tokens"],
                        tokenLogprobs: p.logprobs["token_logprobs"],
                        topLogprobs: p.logprobs["top_logprobs"],
                        textOffset: p.logprobs["text_offset"],
                    },
                finishReason: p["finish_reason"],
            });
        }),
        usage: {
            completionTokens: result.body.usage["completion_tokens"],
            promptTokens: result.body.usage["prompt_tokens"],
            totalTokens: result.body.usage["total_tokens"],
        },
    };
}
/**
 * Gets completions for the provided input prompts.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
async function getCompletions(context, prompt, deploymentId, options = { requestOptions: {} }) {
    const result = await _getCompletionsSend(context, prompt, deploymentId, options);
    return _getCompletionsDeserialize(result);
}
function _getChatCompletionsSend(context, messages, deploymentId, options = { requestOptions: {} }) {
    return context.path("/deployments/{deploymentId}/chat/completions", deploymentId).post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: {
            messages: messages,
            functions: options === null || options === void 0 ? void 0 : options.functions,
            function_call: options === null || options === void 0 ? void 0 : options.functionCall,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
            dataSources: options === null || options === void 0 ? void 0 : options.dataSources,
        } }));
}
function _getChatCompletionsWithAzureExtensionsSend(context, messages, deploymentId, options = { requestOptions: {} }) {
    return context
        .path("/deployments/{deploymentId}/extensions/chat/completions", deploymentId)
        .post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: {
            messages: messages,
            functions: options === null || options === void 0 ? void 0 : options.functions,
            function_call: options === null || options === void 0 ? void 0 : options.functionCall,
            max_tokens: options === null || options === void 0 ? void 0 : options.maxTokens,
            temperature: options === null || options === void 0 ? void 0 : options.temperature,
            top_p: options === null || options === void 0 ? void 0 : options.topP,
            logit_bias: options === null || options === void 0 ? void 0 : options.logitBias,
            user: options === null || options === void 0 ? void 0 : options.user,
            n: options === null || options === void 0 ? void 0 : options.n,
            stop: options === null || options === void 0 ? void 0 : options.stop,
            presence_penalty: options === null || options === void 0 ? void 0 : options.presencePenalty,
            frequency_penalty: options === null || options === void 0 ? void 0 : options.frequencyPenalty,
            stream: options === null || options === void 0 ? void 0 : options.stream,
            model: options === null || options === void 0 ? void 0 : options.model,
            dataSources: options === null || options === void 0 ? void 0 : options.dataSources,
        } }));
}
function _beginAzureBatchImageGenerationSend(context, prompt, options = { requestOptions: {} }) {
    return context.path("/images/generations:submit").post(Object.assign(Object.assign({}, coreClient.operationOptionsToRequestParameters(options)), { body: {
            prompt: prompt,
            n: options === null || options === void 0 ? void 0 : options.n,
            size: options === null || options === void 0 ? void 0 : options.size,
            response_format: options === null || options === void 0 ? void 0 : options.responseFormat,
            user: options === null || options === void 0 ? void 0 : options.user,
        } }));
}
function listCompletions(context, prompt, deploymentName, options = { requestOptions: {} }) {
    const response = _getCompletionsSend(context, prompt, deploymentName, Object.assign(Object.assign({}, options), { stream: true }));
    return getOaiSSEs(response, getCompletionsResult);
}
async function getImages(context, prompt, options = { requestOptions: {} }) {
    const response = await _beginAzureBatchImageGenerationSend(context, prompt, options);
    if (isUnexpected(response)) {
        // Check for response from OpenAI
        const body = response.body;
        if (body.created && body.data) {
            return body;
        }
        throw response.body.error;
    }
    if (response.status === "202") {
        const poller = await getLongRunningPoller(context, response);
        const result = await poller.pollUntilDone();
        return getImageResultsDeserialize(result);
    }
    else {
        return getImageResultsDeserialize(response);
    }
}
function listChatCompletions(context, messages, deploymentName, options = { requestOptions: {} }) {
    const response = _getChatCompletionsSendX(context, messages, deploymentName, Object.assign(Object.assign({}, options), { stream: true }));
    return getOaiSSEs(response, getChatCompletionsResult);
}
/**
 * Gets chat completions for the provided chat messages.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
async function getChatCompletions(context, messages, deploymentId, options = { requestOptions: {} }) {
    const result = await _getChatCompletionsSendX(context, messages, deploymentId, options);
    if (isUnexpected(result)) {
        throw result.body.error;
    }
    return getChatCompletionsResult(result.body);
}
function convertResultTypes({ created, data }) {
    if (typeof data[0].url === "string") {
        return {
            created: new Date(created),
            data: data,
        };
    }
    else {
        return {
            created: new Date(created),
            data: data.map((item) => {
                return {
                    base64Data: item.b64_json,
                };
            }),
        };
    }
}
function getImageResultsDeserialize(response) {
    if (isUnexpected(response) || !response.body.result) {
        throw response.body.error;
    }
    const result = response.body.result;
    return convertResultTypes(result);
}
function _getChatCompletionsSendX(context, messages, deploymentName, options = { requestOptions: {} }) {
    var _a, _b;
    return ((_a = options.azureExtensionOptions) === null || _a === void 0 ? void 0 : _a.extensions)
        ? _getChatCompletionsWithAzureExtensionsSend(context, messages, deploymentName, Object.assign(Object.assign({}, options), { dataSources: (_b = options.azureExtensionOptions) === null || _b === void 0 ? void 0 : _b.extensions }))
        : _getChatCompletionsSend(context, messages, deploymentName, options);
}

// Copyright (c) Microsoft Corporation.
class OpenAIClient {
    constructor(endpointOrOpenAiKey, credOrOptions = {}, options = {}) {
        var _a, _b;
        this._isAzure = false;
        let opts;
        let endpoint;
        let cred;
        if (isCred(credOrOptions)) {
            endpoint = endpointOrOpenAiKey;
            cred = credOrOptions;
            opts = options;
            this._isAzure = true;
        }
        else {
            endpoint = createOpenAIEndpoint(1);
            cred = endpointOrOpenAiKey;
            const { credentials } = credOrOptions, restOpts = tslib.__rest(credOrOptions, ["credentials"]);
            opts = Object.assign({ credentials: {
                    apiKeyHeaderName: (_a = credentials === null || credentials === void 0 ? void 0 : credentials.apiKeyHeaderName) !== null && _a !== void 0 ? _a : "Authorization",
                    scopes: credentials === null || credentials === void 0 ? void 0 : credentials.scopes,
                } }, restOpts);
        }
        this._client = createOpenAI(endpoint, cred, Object.assign(Object.assign({}, opts), (this._isAzure
            ? {}
            : {
                additionalPolicies: [
                    ...((_b = opts.additionalPolicies) !== null && _b !== void 0 ? _b : []),
                    {
                        position: "perCall",
                        policy: getPolicy(),
                    },
                ],
            })));
    }
    /**
     * Returns textual completions as configured for a given prompt.
     * @param deploymentName - Specifies either the model deployment name (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this completions request.
     * @returns The completions for the given prompt.
     */
    getCompletions(deploymentName, prompt, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getCompletions(this._client, prompt, deploymentName, options);
    }
    /**
     * Lists the completions tokens as they become available for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param prompt - The prompt to use for this request.
     * @param options - The completions options for this completions request.
     * @returns An asynchronous iterable of completions tokens.
     */
    listCompletions(deploymentName, prompt, options = {}) {
        this.setModel(deploymentName, options);
        return listCompletions(this._client, prompt, deploymentName, options);
    }
    /**
     * Return the computed embeddings for a given prompt.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param input - The prompt to use for this request.
     * @param options - The embeddings options for this embeddings request.
     * @returns The embeddings for the given prompt.
     */
    getEmbeddings(deploymentName, input, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getEmbeddings(this._client, input, deploymentName, options);
    }
    /**
     * Get chat completions for provided chat context messages.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this completions request.
     * @returns The chat completions for the given chat context messages.
     */
    getChatCompletions(deploymentName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return getChatCompletions(this._client, messages, deploymentName, options);
    }
    /**
     * Lists the chat completions tokens as they become available for a chat context.
     * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
     * @param messages - The chat context messages to use for this request.
     * @param options - The chat completions options for this chat completions request.
     * @returns An asynchronous iterable of chat completions tokens.
     */
    listChatCompletions(deploymentName, messages, options = { requestOptions: {} }) {
        this.setModel(deploymentName, options);
        return listChatCompletions(this._client, messages, deploymentName, options);
    }
    /**
     * Starts the generation of a batch of images from a text caption
     * @param prompt - The prompt to use for this request.
     * @param options - The options for this image request.
     * @returns The image generation response (containing url or base64 data).
     */
    getImages(prompt, options = { requestOptions: {} }) {
        return getImages(this._client, prompt, options);
    }
    setModel(model, options) {
        if (!this._isAzure) {
            options.model = model;
        }
    }
}
function createOpenAIEndpoint(version) {
    return `https://api.openai.com/v${version}`;
}
function isCred(cred) {
    return coreAuth.isTokenCredential(cred) || cred.key !== undefined;
}
function getPolicy() {
    const policy = {
        name: "openAiEndpoint",
        sendRequest: (request, next) => {
            const obj = new URL(request.url);
            const parts = obj.pathname.split("/");
            switch (parts[parts.length - 1]) {
                case "completions":
                    if (parts[parts.length - 2] === "chat") {
                        obj.pathname = `/${parts[1]}/chat/completions`;
                    }
                    else {
                        obj.pathname = `/${parts[1]}/completions`;
                    }
                    break;
                case "embeddings":
                    obj.pathname = `/${parts[1]}/embeddings`;
                    break;
                case "generations:submit":
                    obj.pathname = `/${parts[1]}/images/generations`;
            }
            obj.searchParams.delete("api-version");
            request.url = obj.toString();
            return next(request);
        },
    };
    return policy;
}

Object.defineProperty(exports, 'AzureKeyCredential', {
    enumerable: true,
    get: function () { return coreAuth.AzureKeyCredential; }
});
exports.OpenAIClient = OpenAIClient;
exports.OpenAIKeyCredential = OpenAIKeyCredential;
//# sourceMappingURL=index.cjs.map
